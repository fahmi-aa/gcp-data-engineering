steps:
  - id: 'get-running-job'
    name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: bash
    args:
      - '-c'
      - |
        gcloud dataflow jobs list --filter="iot-\d{10}" --status=active --format="value(JOB_ID)" > ./job_id.txt
  - id: 'install-dependencies'
    name: python:3.8.12-bullseye
    entrypoint: pip
    args: ["install", "-r", "src/dataflow/requirement.txt", "--user"]
  - id: 'build-dataflow-template'
    name: python:3.8.12-bullseye
    entrypoint: python
    args:
      - 'src/dataflow/iot-pipeline.py'
      - '--runner'
      - 'DataflowRunner'
      - '--project=de-porto'
      - '--region=asia-southeast2'
      - '--temp_location=gs://de-porto/temp'
      - '--staging_location=gs://de-porto/staging'
      - '--template_location=gs://de-porto/dataflow-template/iot-pipeline'
  - id: 'deploy-from-template'
    name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: bash
    args:
      - '-c'
      - |
        JOB_NAME="iot-${EPOCHSECONDS}" && \
        gcloud dataflow jobs run "${JOB_NAME}" \
          --gcs-location=gs://de-porto/dataflow-template/iot-pipeline
          --enable-streaming-engine
          --max-workers=1
          --num-workers=1
          --worker-machine-type=n1-standard-1
          --region=asia-southeast2
  - id: 'drain-existing-job'
    name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: bash
    args:
      - '-c'
      - |
        JOB_ID=$(cat ./job_id.txt) && gcloud dataflow jobs drain ${JOB_ID:-"anything"}

options:
  logging: CLOUD_LOGGING_ONLY